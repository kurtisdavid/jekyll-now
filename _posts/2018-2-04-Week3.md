---
layout: post
title: Week 3
---

### What did you do this past week?
This week I finished the Collatz project. It took me a little longer than I thought, but hopefully I covered everything in the rubric. I also tried to get started on my homework for other classes, since they will be due this coming week. In terms of class content, I learned more about Python exceptions - I didn't know the hierarchy of the except clauses. 

### What's in your way?
I was feeling a bit paranoid about the tight rubric for Collatz, so I think I overcomplicated some parts of the project. I should probably avoid doing this again, and view the rubric more as a gift, than a curse. Also, my homework schedule is more irregular this semester, one week I only have SWE projects due, and the other week I have Algo, Vision and Numerical Methods homework is due. I guess this gives me more time on work, however, I have to stay sharp so I can stay on a solid schedule.

### What will you do next week?
I'll be slaving away finishing the aforementioned work as well as starting the new SWE project. Our group is currently looking for one more in the 11-12 section, so hopefully that will be taken care of soon. Outside of school, I'll be attending the Data Open hosted by Citadel! It's a data hack-a-thon, so I'm excited for that. I also just got the new Dragon Ball FighterZ game, so that should be a good breather between all the work.

### What's my experience of the class?
I used to think the readings would be the hard part of the quizzes, but my worst results have actually been relevant to what Downing taught during class. I need to step it up, since the number of dropped quizzes isn't that big. Lectures have been more interesting lately, as we're getting deeper into Python. Also, the way Downing does his announcements at the beginning of class actually remind me of church when the priest makes some announcements on the behalf of organizations. It's not bad, since we get to know what's happening with a few orgs in CS.

### What's my pick-of-the-week or tip-of-the-week?
If you're interested in deep learning, one of the most important concepts to understand is how to actually train a neural network. The most popular method is backpropagation, which utilizes chain-rule to update the weights based on the training error of your dataset. But to actually see how it works, the easiest way is to just sit down and do the math yourself. To help brush up on the calculus needed, you can take a look at this article: [The Matrix Calculus You Need For Deep Learning](http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html)!